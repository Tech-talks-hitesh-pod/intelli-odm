{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelli-ODM (Intelligent On-Demand Merchandising) Demo\n",
    "\n",
    "This notebook demonstrates the complete workflow of the Intelli-ODM system, from product analysis to procurement recommendations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Intelli-ODM system uses AI agents to:\n",
    "1. **Data Ingestion**: Process and validate product data\n",
    "2. **Attribute Analysis**: Extract product attributes and find comparable items\n",
    "3. **Demand Forecasting**: Predict future demand using multiple approaches\n",
    "4. **Procurement Optimization**: Generate optimal procurement recommendations\n",
    "\n",
    "Let's walk through each step with real examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the parent directory to Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from config.settings import Settings\n",
    "from shared_knowledge_base import SharedKnowledgeBase\n",
    "from utils.llm_client import LLMClientFactory\n",
    "from agents.orchestrator_agent import OrchestratorAgent\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup\n",
    "\n",
    "First, let's set up our LLM client and knowledge base. This example supports both Ollama (local) and OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "settings = Settings()\n",
    "\n",
    "print(f\"üîß Using LLM Provider: {settings.llm_provider}\")\n",
    "\n",
    "# Create LLM client\n",
    "if settings.llm_provider == \"ollama\":\n",
    "    llm_config = {\n",
    "        \"provider\": \"ollama\",\n",
    "        \"base_url\": settings.ollama_base_url,\n",
    "        \"model\": settings.ollama_model,\n",
    "        \"timeout\": 300\n",
    "    }\n",
    "elif settings.llm_provider == \"openai\":\n",
    "    if not settings.openai_api_key:\n",
    "        print(\"‚ùå OpenAI API key not found. Please set OPENAI_API_KEY environment variable.\")\n",
    "        print(\"   Falling back to Ollama...\")\n",
    "        llm_config = {\"provider\": \"ollama\", \"base_url\": \"http://localhost:11434\", \"model\": \"llama3:8b\"}\n",
    "    else:\n",
    "        llm_config = {\n",
    "            \"provider\": \"openai\",\n",
    "            \"api_key\": settings.openai_api_key,\n",
    "            \"model\": settings.openai_model\n",
    "        }\n",
    "\n",
    "try:\n",
    "    llm_client = LLMClientFactory.create_client(llm_config)\n",
    "    print(f\"‚úÖ LLM client created successfully\")\n",
    "    \n",
    "    # Test LLM availability\n",
    "    if llm_client.is_available():\n",
    "        print(f\"üü¢ LLM service is available and ready\")\n",
    "    else:\n",
    "        print(f\"üü° LLM service not available - some features will use fallbacks\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create LLM client: {e}\")\n",
    "    print(\"   Please ensure Ollama is running or OpenAI API key is set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knowledge base\n",
    "try:\n",
    "    kb = SharedKnowledgeBase(persist_directory=\"../data/chroma_db\")\n",
    "    print(f\"‚úÖ Knowledge base initialized\")\n",
    "    print(f\"üìä Current products in knowledge base: {kb.get_collection_size()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize knowledge base: {e}\")\n",
    "\n",
    "# Initialize orchestrator\n",
    "try:\n",
    "    orchestrator = OrchestratorAgent(llm_client, kb)\n",
    "    print(f\"‚úÖ Orchestrator agent initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize orchestrator: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Product Descriptions\n",
    "\n",
    "Let's define some sample product descriptions to analyze. These represent real-world product listings that might be found in e-commerce catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample product descriptions\n",
    "sample_products = [\n",
    "    \"Classic white cotton t-shirt with crew neck, short sleeves, regular fit, perfect for casual wear. Made from 100% premium cotton.\",\n",
    "    \"Navy blue denim jeans, slim fit, straight leg, button fly closure. High-quality denim material with slight stretch for comfort.\",\n",
    "    \"Elegant black cocktail dress, sleeveless design with V-neckline, knee-length, made from premium chiffon fabric. Perfect for formal occasions.\",\n",
    "    \"Red polo shirt for men, cotton blend fabric, collar with 3-button placket, short sleeves, athletic fit design.\",\n",
    "    \"Women's floral print summer dress, midi length, cap sleeves, round neckline, lightweight crepe material. Ideal for spring and summer.\"\n",
    "]\n",
    "\n",
    "print(f\"üì¶ Sample products to analyze: {len(sample_products)}\")\n",
    "for i, desc in enumerate(sample_products, 1):\n",
    "    print(f\"{i}. {desc[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Inventory and Sales Data\n",
    "\n",
    "Let's create some sample inventory levels and sales history to make our analysis more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inventory data\n",
    "inventory_data = {\n",
    "    \"product_1\": 150,  # White t-shirt\n",
    "    \"product_2\": 80,   # Navy jeans\n",
    "    \"product_3\": 25,   # Black dress\n",
    "    \"product_4\": 120,  # Red polo\n",
    "    \"product_5\": 40    # Floral dress\n",
    "}\n",
    "\n",
    "# Generate sample sales history (last 30 days)\n",
    "def generate_sales_history(product_count=5, days=30):\n",
    "    import random\n",
    "    sales_history = []\n",
    "    \n",
    "    base_date = datetime.now() - timedelta(days=days)\n",
    "    \n",
    "    for day in range(days):\n",
    "        date = base_date + timedelta(days=day)\n",
    "        \n",
    "        for product_id in range(1, product_count + 1):\n",
    "            # Generate realistic sales with some seasonality and randomness\n",
    "            base_sales = {\n",
    "                1: 15,  # T-shirt (popular)\n",
    "                2: 8,   # Jeans (steady)\n",
    "                3: 3,   # Dress (lower volume)\n",
    "                4: 10,  # Polo (moderate)\n",
    "                5: 5    # Floral dress (seasonal)\n",
    "            }\n",
    "            \n",
    "            # Add some randomness and day-of-week effects\n",
    "            weekday_factor = 1.3 if date.weekday() < 5 else 0.7  # Weekday vs weekend\n",
    "            random_factor = random.uniform(0.7, 1.4)\n",
    "            \n",
    "            daily_sales = max(0, int(base_sales[product_id] * weekday_factor * random_factor))\n",
    "            \n",
    "            if daily_sales > 0:\n",
    "                sales_history.append({\n",
    "                    \"product_id\": f\"product_{product_id}\",\n",
    "                    \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "                    \"quantity\": daily_sales,\n",
    "                    \"revenue\": daily_sales * random.uniform(40, 80)  # Variable pricing\n",
    "                })\n",
    "    \n",
    "    return sales_history\n",
    "\n",
    "sales_history = generate_sales_history()\n",
    "\n",
    "print(f\"üìà Generated {len(sales_history)} sales records\")\n",
    "print(f\"üí∞ Sample inventory levels: {inventory_data}\")\n",
    "\n",
    "# Show sales summary\n",
    "sales_df = pd.DataFrame(sales_history)\n",
    "sales_summary = sales_df.groupby('product_id').agg({\n",
    "    'quantity': 'sum',\n",
    "    'revenue': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nüìä Sales Summary (Last 30 days):\")\n",
    "print(sales_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute Complete Workflow\n",
    "\n",
    "Now let's run the complete Intelli-ODM workflow using our orchestrator agent. This will execute all phases of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting complete Intelli-ODM workflow...\\n\")\n",
    "\n",
    "# Execute the complete workflow\n",
    "try:\n",
    "    results = orchestrator.run_complete_workflow(\n",
    "        product_descriptions=sample_products,\n",
    "        inventory_data=inventory_data,\n",
    "        sales_history=sales_history\n",
    "    )\n",
    "    \n",
    "    if results['success']:\n",
    "        print(\"‚úÖ Workflow completed successfully!\")\n",
    "        print(f\"üìã Session ID: {results['session_id']}\")\n",
    "        print(f\"‚≠ê Confidence Score: {results['confidence_score']:.2f}\")\n",
    "        print(f\"üìä Success Rate: {results['metrics']['success_rate']:.1%}\")\n",
    "    else:\n",
    "        print(\"‚ùå Workflow failed:\")\n",
    "        print(f\"Error: {results.get('error', 'Unknown error')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Workflow execution failed: {e}\")\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Results\n",
    "\n",
    "Let's examine the results from each phase of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results['success']:\n",
    "    print(\"üìã EXECUTIVE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(results['executive_summary'])\n",
    "    print()\n",
    "    \n",
    "    print(\"üîç KEY INSIGHTS\")\n",
    "    print(\"=\" * 50)\n",
    "    for insight in results['key_insights']:\n",
    "        print(f\"‚Ä¢ {insight}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üìä EXECUTION METRICS\")\n",
    "    print(\"=\" * 50)\n",
    "    metrics = results['metrics']\n",
    "    print(f\"Products Processed: {metrics['total_products_processed']}\")\n",
    "    print(f\"Successful Analyses: {metrics['successful_analyses']}\")\n",
    "    print(f\"Forecasts Generated: {metrics['forecasts_generated']}\")\n",
    "    print(f\"Procurement Recommendations: {metrics['procurement_recommendations']}\")\n",
    "    print(f\"Overall Success Rate: {metrics['success_rate']:.1%}\")\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è Execution Times:\")\n",
    "    for phase, time_taken in metrics['execution_times'].items():\n",
    "        print(f\"  {phase}: {time_taken:.2f} seconds\")\n",
    "else:\n",
    "    print(\"‚ùå No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Product Attribute Analysis\n",
    "\n",
    "Let's examine the extracted product attributes and comparable products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results['success']:\n",
    "    attribute_results = results['detailed_results']['attribute_analysis']\n",
    "    \n",
    "    print(\"üè∑Ô∏è PRODUCT ATTRIBUTES ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    attributes_data = []\n",
    "    \n",
    "    for product_id, attrs in attribute_results.get('product_attributes', {}).items():\n",
    "        attributes_data.append({\n",
    "            'Product': product_id,\n",
    "            'Category': attrs.get('category', 'Unknown'),\n",
    "            'Material': attrs.get('material', 'Unknown'),\n",
    "            'Color': attrs.get('color', 'Unknown'),\n",
    "            'Style': attrs.get('style', 'Unknown'),\n",
    "            'Target Gender': attrs.get('target_gender', 'Unknown'),\n",
    "            'Confidence': f\"{attrs.get('confidence', 0):.2f}\"\n",
    "        })\n",
    "    \n",
    "    if attributes_data:\n",
    "        attrs_df = pd.DataFrame(attributes_data)\n",
    "        print(attrs_df.to_string(index=False))\n",
    "        \n",
    "        # Show category distribution\n",
    "        print(\"\\nüìä Category Distribution:\")\n",
    "        category_counts = attrs_df['Category'].value_counts()\n",
    "        for category, count in category_counts.items():\n",
    "            print(f\"  {category}: {count} products\")\n",
    "    else:\n",
    "        print(\"No product attributes extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demand Forecasting Results\n",
    "\n",
    "Let's visualize the demand forecasts for our products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results['success']:\n",
    "    forecast_results = results['detailed_results']['demand_forecasting']\n",
    "    \n",
    "    print(\"üìà DEMAND FORECASTING RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Extract forecast data\n",
    "    forecast_data = []\n",
    "    \n",
    "    for product_id, forecast in forecast_results.get('demand_forecasts', {}).items():\n",
    "        if isinstance(forecast.get('forecast'), dict):\n",
    "            forecast_qty = forecast['forecast'].get('quantity', 0)\n",
    "            confidence = forecast['forecast'].get('confidence', 0)\n",
    "            trend = forecast['forecast'].get('trend', {}).get('direction', 'stable')\n",
    "        else:\n",
    "            forecast_qty = forecast.get('forecast', 0)\n",
    "            confidence = forecast.get('confidence', 0.5)\n",
    "            trend = 'stable'\n",
    "        \n",
    "        forecast_data.append({\n",
    "            'Product': product_id,\n",
    "            'Forecast (30 days)': int(forecast_qty),\n",
    "            'Trend': trend,\n",
    "            'Confidence': f\"{confidence:.2f}\",\n",
    "            'Current Inventory': inventory_data.get(product_id, 0)\n",
    "        })\n",
    "    \n",
    "    if forecast_data:\n",
    "        forecast_df = pd.DataFrame(forecast_data)\n",
    "        print(forecast_df.to_string(index=False))\n",
    "        \n",
    "        # Calculate inventory coverage\n",
    "        forecast_df['Coverage (days)'] = (\n",
    "            forecast_df['Current Inventory'] / \n",
    "            (forecast_df['Forecast (30 days)'] / 30)\n",
    "        ).round(1)\n",
    "        \n",
    "        print(\"\\nüìä Inventory Coverage Analysis:\")\n",
    "        for _, row in forecast_df.iterrows():\n",
    "            coverage = row['Coverage (days)']\n",
    "            status = \"üî¥ Critical\" if coverage < 15 else \"üü° Low\" if coverage < 30 else \"üü¢ Adequate\"\n",
    "            print(f\"  {row['Product']}: {coverage} days {status}\")\n",
    "    else:\n",
    "        print(\"No demand forecasts available\")\n",
    "        \n",
    "    # Visualize forecasts\n",
    "    if forecast_data:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        products = [item['Product'] for item in forecast_data]\n",
    "        forecasts = [item['Forecast (30 days)'] for item in forecast_data]\n",
    "        inventory = [item['Current Inventory'] for item in forecast_data]\n",
    "        \n",
    "        x = range(len(products))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar([i - width/2 for i in x], forecasts, width, label='Forecast (30 days)', alpha=0.8)\n",
    "        plt.bar([i + width/2 for i in x], inventory, width, label='Current Inventory', alpha=0.8)\n",
    "        \n",
    "        plt.xlabel('Products')\n",
    "        plt.ylabel('Quantity')\n",
    "        plt.title('Demand Forecast vs Current Inventory')\n",
    "        plt.xticks(x, products, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Procurement Recommendations\n",
    "\n",
    "Finally, let's examine the procurement optimization results and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results['success']:\n",
    "    procurement_results = results['detailed_results']['procurement_optimization']\n",
    "    \n",
    "    print(\"üõí PROCUREMENT RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recommendations = results['recommendations']['procurement']\n",
    "    \n",
    "    if recommendations:\n",
    "        # Create recommendations DataFrame\n",
    "        rec_data = []\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            rec_data.append({\n",
    "                'Product': rec['product_id'],\n",
    "                'Action': rec['action'],\n",
    "                'Quantity': rec['quantity'],\n",
    "                'Cost': f\"${rec['estimated_cost']:,.0f}\",\n",
    "                'Priority': rec['priority'],\n",
    "                'Timeline': rec['timeline'],\n",
    "                'Supplier': rec['supplier']['name']\n",
    "            })\n",
    "        \n",
    "        rec_df = pd.DataFrame(rec_data)\n",
    "        print(rec_df.to_string(index=False))\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_investment = sum(rec['estimated_cost'] for rec in recommendations)\n",
    "        total_quantity = sum(rec['quantity'] for rec in recommendations)\n",
    "        high_priority_count = len([r for r in recommendations if r['priority'] == 'High'])\n",
    "        \n",
    "        print(f\"\\nüí∞ PROCUREMENT SUMMARY\")\n",
    "        print(f\"Total Investment Required: ${total_investment:,.0f}\")\n",
    "        print(f\"Total Quantity to Procure: {total_quantity:,} units\")\n",
    "        print(f\"High Priority Items: {high_priority_count}\")\n",
    "        print(f\"Average Cost per Unit: ${total_investment/total_quantity:.2f}\")\n",
    "        \n",
    "        # Priority breakdown\n",
    "        priority_counts = {}\n",
    "        for rec in recommendations:\n",
    "            priority = rec['priority']\n",
    "            priority_counts[priority] = priority_counts.get(priority, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüìä Priority Breakdown:\")\n",
    "        for priority, count in priority_counts.items():\n",
    "            print(f\"  {priority}: {count} items\")\n",
    "            \n",
    "        # Visualize procurement recommendations\n",
    "        if len(recommendations) > 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            products = [rec['product_id'] for rec in recommendations]\n",
    "            costs = [rec['estimated_cost'] for rec in recommendations]\n",
    "            priorities = [rec['priority'] for rec in recommendations]\n",
    "            \n",
    "            # Color code by priority\n",
    "            colors = {'High': 'red', 'Medium': 'orange', 'Low': 'green'}\n",
    "            bar_colors = [colors.get(p, 'blue') for p in priorities]\n",
    "            \n",
    "            plt.bar(products, costs, color=bar_colors, alpha=0.7)\n",
    "            plt.xlabel('Products')\n",
    "            plt.ylabel('Procurement Cost ($)')\n",
    "            plt.title('Procurement Recommendations by Priority')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            # Create legend\n",
    "            handles = [plt.Rectangle((0,0),1,1, color=colors[p], alpha=0.7) for p in colors.keys()]\n",
    "            plt.legend(handles, colors.keys(), title='Priority')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"No procurement recommendations generated\")\n",
    "        \n",
    "    # Strategic recommendations\n",
    "    strategic_recs = results['recommendations'].get('strategic', [])\n",
    "    if strategic_recs:\n",
    "        print(f\"\\nüéØ STRATEGIC RECOMMENDATIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, rec in enumerate(strategic_recs, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "else:\n",
    "    print(\"‚ùå No results available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Analysis and System Health\n",
    "\n",
    "Let's examine any errors or warnings from the workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    print(\"üîç SYSTEM HEALTH CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    errors = results.get('errors', [])\n",
    "    if errors:\n",
    "        print(f\"‚ö†Ô∏è Errors encountered: {len(errors)}\")\n",
    "        for i, error in enumerate(errors, 1):\n",
    "            print(f\"{i}. {error}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No errors encountered\")\n",
    "    \n",
    "    # Check phase-specific errors\n",
    "    if 'detailed_results' in results:\n",
    "        phase_errors = {}\n",
    "        for phase_name, phase_data in results['detailed_results'].items():\n",
    "            phase_errors[phase_name] = len(phase_data.get('errors', []))\n",
    "        \n",
    "        print(f\"\\nüìä Phase Error Breakdown:\")\n",
    "        for phase, error_count in phase_errors.items():\n",
    "            status = \"‚úÖ\" if error_count == 0 else \"‚ö†Ô∏è\"\n",
    "            print(f\"  {status} {phase}: {error_count} errors\")\n",
    "    \n",
    "    # System recommendations\n",
    "    print(f\"\\nüîß SYSTEM RECOMMENDATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    confidence = results.get('confidence_score', 0)\n",
    "    success_rate = results.get('metrics', {}).get('success_rate', 0)\n",
    "    \n",
    "    if confidence < 0.7:\n",
    "        print(\"‚Ä¢ Consider improving data quality or LLM configuration\")\n",
    "    \n",
    "    if success_rate < 0.8:\n",
    "        print(\"‚Ä¢ Check LLM service availability and network connectivity\")\n",
    "    \n",
    "    if len(errors) > 0:\n",
    "        print(\"‚Ä¢ Review error logs and consider adjusting agent parameters\")\n",
    "    \n",
    "    if confidence >= 0.8 and success_rate >= 0.8 and len(errors) == 0:\n",
    "        print(\"‚úÖ System is operating optimally!\")\n",
    "else:\n",
    "    print(\"‚ùå No results available for health check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results\n",
    "\n",
    "Let's export our results for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results['success']:\n",
    "    # Create export directory\n",
    "    export_dir = \"exports\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Export complete results as JSON\n",
    "    json_file = f\"{export_dir}/intelli_odm_results_{timestamp}.json\"\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    print(f\"‚úÖ Results exported to: {json_file}\")\n",
    "    \n",
    "    # Export recommendations as CSV\n",
    "    if results['recommendations']['procurement']:\n",
    "        rec_data = []\n",
    "        for rec in results['recommendations']['procurement']:\n",
    "            rec_data.append({\n",
    "                'Product ID': rec['product_id'],\n",
    "                'Action': rec['action'],\n",
    "                'Quantity': rec['quantity'],\n",
    "                'Estimated Cost': rec['estimated_cost'],\n",
    "                'Priority': rec['priority'],\n",
    "                'Timeline': rec['timeline'],\n",
    "                'Supplier': rec['supplier']['name'],\n",
    "                'Urgency Score': rec['urgency'],\n",
    "                'Justification': rec['justification']\n",
    "            })\n",
    "        \n",
    "        rec_df = pd.DataFrame(rec_data)\n",
    "        csv_file = f\"{export_dir}/procurement_recommendations_{timestamp}.csv\"\n",
    "        rec_df.to_csv(csv_file, index=False)\n",
    "        print(f\"‚úÖ Recommendations exported to: {csv_file}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    report_file = f\"{export_dir}/executive_summary_{timestamp}.txt\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"INTELLI-ODM ANALYSIS REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Session ID: {results['session_id']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"EXECUTIVE SUMMARY\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"{results['executive_summary']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"KEY METRICS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        metrics = results['metrics']\n",
    "        f.write(f\"Products Processed: {metrics['total_products_processed']}\\n\")\n",
    "        f.write(f\"Success Rate: {metrics['success_rate']:.1%}\\n\")\n",
    "        f.write(f\"Confidence Score: {results['confidence_score']:.2f}\\n\")\n",
    "        f.write(f\"Total Investment: ${results['recommendations']['procurement'][0]['estimated_cost'] if results['recommendations']['procurement'] else 0:,.0f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"KEY INSIGHTS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        for insight in results['key_insights']:\n",
    "            f.write(f\"‚Ä¢ {insight}\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Summary report exported to: {report_file}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ All exports saved to '{export_dir}' directory\")\n",
    "else:\n",
    "    print(\"‚ùå No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete Intelli-ODM workflow:\n",
    "\n",
    "1. **Setup**: Configured LLM client and knowledge base\n",
    "2. **Data Preparation**: Created sample products, inventory, and sales data\n",
    "3. **Workflow Execution**: Ran the complete orchestrated analysis\n",
    "4. **Result Analysis**: Examined attributes, forecasts, and recommendations\n",
    "5. **Export**: Saved results for further use\n",
    "\n",
    "The system successfully analyzed products, generated demand forecasts, and provided optimized procurement recommendations with confidence scoring and error handling.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Integrate with real product catalogs and sales data\n",
    "2. Fine-tune agent parameters based on your specific domain\n",
    "3. Set up automated workflows for regular analysis\n",
    "4. Customize the UI for your business needs\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- Check the documentation in the `docs/` folder\n",
    "- Review agent configurations in `config/`\n",
    "- Examine the knowledge base setup in `shared_knowledge_base.py`\n",
    "- Test individual agents in isolation for debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}